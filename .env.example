# LLM Server Configuration
# Change to your llama.cpp server address (e.g., http://192.168.1.95:8080)
LLAMA_CPP_URL=http://localhost:8080
LLAMA_CPP_MODEL=gpt-oss-120b
LLAMA_CPP_TIMEOUT=120

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password_here
NEO4J_DATABASE=neo4j

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=3000
LOG_LEVEL=INFO

# Memory Configuration
MIN_CONFIDENCE_THRESHOLD=0.5
MAX_CONTEXT_MEMORIES=10
EXTRACTION_ENABLED=true

# Conversation Configuration
CONVERSATION_REASONING_LEVEL=low
EXTRACTION_REASONING_LEVEL=medium
